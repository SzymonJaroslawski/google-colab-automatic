{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47kV9o1Ni8GH"
      },
      "source": [
        "# **Colab Pro notebook from https://github.com/TheLastBen/fast-stable-diffusion**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Y9EBc437WDOs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "4ed3eba5e6dd4a65bfc6226d50c9ee50",
            "24787703db6a4e91b0d4b26785f7a4be",
            "49a2b5c8e20e4639a63c3deb66f718d2"
          ]
        },
        "outputId": "9d2fe759-714f-470b-d02f-c37f969f90d0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Button(button_style='success', description='✔ Done', disabled=True, layout=Layout(min_width='50px'), style=But…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4ed3eba5e6dd4a65bfc6226d50c9ee50"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "#@markdown # Connect Google Drive\n",
        "from google.colab import drive\n",
        "from IPython.display import clear_output\n",
        "import ipywidgets as widgets\n",
        "import os\n",
        "\n",
        "def inf(msg, style, wdth): inf = widgets.Button(description=msg, disabled=True, button_style=style, layout=widgets.Layout(min_width=wdth));display(inf)\n",
        "Shared_Drive = \"test\" #@param {type:\"string\"}\n",
        "#@markdown - Leave empty if you're not using a shared drive\n",
        "\n",
        "print(\"\u001b[0;33mConnecting...\")\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "if Shared_Drive!=\"\" and os.path.exists(\"/content/gdrive/Shareddrives\"):\n",
        "  mainpth=\"Shareddrives/\"+Shared_Drive\n",
        "else:\n",
        "  mainpth=\"MyDrive\"\n",
        "\n",
        "clear_output()\n",
        "inf('\\u2714 Done','success', '50px')\n",
        "\n",
        "#@markdown ---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "CFWtw-6EPrKi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "461e024356d14032b6a5d8c926f4fc76",
            "b7034d13a1314e52b3ce38764988c488",
            "19f16ccd7c0148638b7f68d01fdddc0f"
          ]
        },
        "outputId": "5cb4ef09-3180-4551-8bf8-371a0d33cd9f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Button(button_style='success', description='✔ Done', disabled=True, layout=Layout(min_width='50px'), style=But…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "461e024356d14032b6a5d8c926f4fc76"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "#@markdown # Install/Update AUTOMATIC1111 repo\n",
        "from IPython.utils import capture\n",
        "from IPython.display import clear_output\n",
        "from subprocess import getoutput\n",
        "import ipywidgets as widgets\n",
        "import sys\n",
        "import fileinput\n",
        "import os\n",
        "import time\n",
        "import base64\n",
        "import requests\n",
        "from urllib.request import urlopen, Request\n",
        "from urllib.parse import urlparse, parse_qs, unquote\n",
        "from tqdm import tqdm\n",
        "import six\n",
        "\n",
        "\n",
        "blsaphemy=base64.b64decode((\"ZWJ1aQ==\").encode('ascii')).decode('ascii')\n",
        "\n",
        "if not os.path.exists(\"/content/gdrive\"):\n",
        "  print('\u001b[1;31mGdrive not connected, using temporary colab storage ...')\n",
        "  time.sleep(4)\n",
        "  mainpth=\"MyDrive\"\n",
        "  !mkdir -p /content/gdrive/$mainpth\n",
        "  Shared_Drive=\"\"\n",
        "\n",
        "if Shared_Drive!=\"\" and not os.path.exists(\"/content/gdrive/Shareddrives\"):\n",
        "  print('\u001b[1;31mShared drive not detected, using default MyDrive')\n",
        "  mainpth=\"MyDrive\"\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "  def inf(msg, style, wdth): inf = widgets.Button(description=msg, disabled=True, button_style=style, layout=widgets.Layout(min_width=wdth));display(inf)\n",
        "  fgitclone = \"git clone --depth 1\"\n",
        "  !git clone -q --depth 1 --branch main https://github.com/TheLastBen/diffusers\n",
        "  %mkdir -p /content/gdrive/$mainpth/sd\n",
        "  %cd /content/gdrive/$mainpth/sd\n",
        "  !git clone -q --branch master https://github.com/AUTOMATIC1111/stable-diffusion-w$blsaphemy\n",
        "  !mkdir -p /content/gdrive/$mainpth/sd/stable-diffusion-w$blsaphemy/cache/\n",
        "  os.environ['TRANSFORMERS_CACHE']=f\"/content/gdrive/{mainpth}/sd/stable-diffusion-w\"+blsaphemy+\"/cache\"\n",
        "  os.environ['TORCH_HOME'] = f\"/content/gdrive/{mainpth}/sd/stable-diffusion-w\"+blsaphemy+\"/cache\"\n",
        "  !mkdir -p /content/gdrive/$mainpth/sd/stable-diffusion-w$blsaphemy/repositories\n",
        "  !git clone https://github.com/AUTOMATIC1111/stable-diffusion-w$blsaphemy-assets /content/gdrive/$mainpth/sd/stable-diffusion-w$blsaphemy/repositories/stable-diffusion-webui-assets\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "  %cd /content/gdrive/$mainpth/sd/stable-diffusion-w$blsaphemy/\n",
        "  !git reset --hard\n",
        "  !git checkout master\n",
        "  time.sleep(1)\n",
        "  !rm webui.sh\n",
        "  !git pull\n",
        "clear_output()\n",
        "inf('\\u2714 Done','success', '50px')\n",
        "\n",
        "#@markdown ---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ZGV_5H4xrOSp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "d6442e75ce3344df8f7c38c8d6cb75c6",
            "b02077bf283d4fd296fb70bc69d6d5e9",
            "6a7da0e852a94a92b0a0ae1759f107cc"
          ]
        },
        "outputId": "5f40830d-0e99-405d-b535-622782de44a7"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Button(button_style='success', description='✔ Done', disabled=True, layout=Layout(min_width='50px'), style=But…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d6442e75ce3344df8f7c38c8d6cb75c6"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "#@markdown # Requirements\n",
        "\n",
        "print('\u001b[1;32mInstalling requirements...')\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "  !rm -r /usr/local/lib/python3.11/dist-packages/gradio*\n",
        "  %cd /content/\n",
        "  !wget -q -i https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/Dependencies/A1111.txt\n",
        "  !dpkg -i *.deb\n",
        "  if not os.path.exists('/content/gdrive/'+mainpth+'/sd/stablediffusion'):\n",
        "    !tar -C /content/gdrive/$mainpth --zstd -xf sd_mrep.tar.zst\n",
        "  !tar -C / --zstd -xf gcolabdeps.tar.zst\n",
        "  !rm *.deb | rm *.zst | rm *.txt\n",
        "  if not os.path.exists('gdrive/'+mainpth+'/sd/libtcmalloc/libtcmalloc_minimal.so.4'):\n",
        "    %env CXXFLAGS=-std=c++14\n",
        "    !wget -q https://github.com/gperftools/gperftools/releases/download/gperftools-2.5/gperftools-2.5.tar.gz && tar zxf gperftools-2.5.tar.gz && mv gperftools-2.5 gperftools\n",
        "    !wget -q https://github.com/TheLastBen/fast-stable-diffusion/raw/main/AUTOMATIC1111_files/Patch\n",
        "    %cd /content/gperftools\n",
        "    !patch -p1 < /content/Patch\n",
        "    !./configure --enable-minimal --enable-libunwind --enable-frame-pointers --enable-dynamic-sized-delete-support --enable-sized-delete --enable-emergency-malloc; make -j4\n",
        "    !mkdir -p /content/gdrive/$mainpth/sd/libtcmalloc && cp .libs/libtcmalloc*.so* /content/gdrive/$mainpth/sd/libtcmalloc\n",
        "    %env LD_PRELOAD=/content/gdrive/$mainpth/sd/libtcmalloc/libtcmalloc_minimal.so.4\n",
        "    %cd /content\n",
        "    !rm *.tar.gz Patch && rm -r /content/gperftools\n",
        "  else:\n",
        "    %env LD_PRELOAD=/content/gdrive/$mainpth/sd/libtcmalloc/libtcmalloc_minimal.so.4\n",
        "\n",
        "  !pip uninstall jax -y\n",
        "  !pip install wandb==0.15.12 pydantic==1.10.2 numpy==1.24.3 controlnet_aux --no-deps -qq\n",
        "  !pip install diffusers accelerate -U --no-deps -qq\n",
        "  !rm -r /usr/local/lib/python3.11/dist-packages/tensorflow*\n",
        "  os.environ['PYTHONWARNINGS'] = 'ignore'\n",
        "  !sed -i 's@text = _formatwarnmsg(msg)@text =\\\"\\\"@g' /usr/lib/python3.11/warnings.py\n",
        "  !sed -i 's@from pytorch_lightning.loggers.wandb import WandbLogger  # noqa: F401@@g' /usr/local/lib/python3.11/dist-packages/pytorch_lightning/loggers/__init__.py\n",
        "  !sed -i 's@from .mailbox import ContextCancelledError@@g' /usr/local/lib/python3.11/dist-packages/wandb/sdk/lib/retry.py\n",
        "  !sed -i 's@raise ContextCancelledError(\"retry timeout\")@print(\"retry timeout\")@g' /usr/local/lib/python3.11/dist-packages/wandb/sdk/lib/retry.py\n",
        "\n",
        "clear_output()\n",
        "inf('\\u2714 Done','success', '50px')\n",
        "\n",
        "#@markdown ---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "p4wj_txjP3TC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "5d7cb8b4df604cdeb8a6fd426ee4e023",
            "0ca3c9762cd1460e86b62e0d59a3c967",
            "7812a22b722f46a5a38b893838ffdfb6"
          ]
        },
        "outputId": "5a054cb6-2b2d-472d-f37c-c202416aae9e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Button(button_style='success', description='✔ Model downloaded, using the custom model.', disabled=True, layou…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5d7cb8b4df604cdeb8a6fd426ee4e023"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "#@markdown # Model Download/Load\n",
        "\n",
        "import gdown\n",
        "from gdown.download import get_url_from_gdrive_confirmation\n",
        "import re\n",
        "\n",
        "Use_Temp_Storage = True #@param {type:\"boolean\"}\n",
        "#@markdown - If not, make sure you have enough space on your gdrive\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "Model_Version = \"SDXL\" #@param [\"SDXL\", \"1.5\", \"v1.5 Inpainting\", \"V2.1-768px\"]\n",
        "\n",
        "#@markdown Or\n",
        "PATH_to_MODEL = \"\" #@param {type:\"string\"}\n",
        "#@markdown - Insert the full path of your custom model or to a folder containing multiple models\n",
        "\n",
        "#@markdown Or\n",
        "MODEL_LINK = \"https://civitai-delivery-worker-prod.5ac0637cfd0766c97916cefa3764fbdf.r2.cloudflarestorage.com/model/4682393/janku20v402020based20noob.t3Cr.safetensors?X-Amz-Expires=86400&response-content-disposition=attachment%3B%20filename%3D%22JANKUV4NSFWTrainedNoobaiEPS_v40.safetensors%22&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=e01358d793ad6966166af8b3064953ad/20250621/us-east-1/s3/aws4_request&X-Amz-Date=20250621T150819Z&X-Amz-SignedHeaders=host&X-Amz-Signature=f6b3a8891d8c2c1a19e0b1681d346ef5e3d630b74a5eefc12fbcd3df1c2cdeb0\" #@param {type:\"string\"}\n",
        "\n",
        "\n",
        "def getsrc(url):\n",
        "    parsed_url = urlparse(url)\n",
        "    if parsed_url.netloc == 'civitai.com':\n",
        "        src='civitai'\n",
        "    elif parsed_url.netloc == 'drive.google.com':\n",
        "        src='gdrive'\n",
        "    elif parsed_url.netloc == 'huggingface.co':\n",
        "        src='huggingface'\n",
        "    else:\n",
        "        src='others'\n",
        "    return src\n",
        "\n",
        "src=getsrc(MODEL_LINK)\n",
        "\n",
        "def get_name(url, gdrive):\n",
        "    if not gdrive:\n",
        "        response = requests.get(url, allow_redirects=False)\n",
        "        if \"Location\" in response.headers:\n",
        "            redirected_url = response.headers[\"Location\"]\n",
        "            quer = parse_qs(urlparse(redirected_url).query)\n",
        "            if \"response-content-disposition\" in quer:\n",
        "                disp_val = quer[\"response-content-disposition\"][0].split(\";\")\n",
        "                for vals in disp_val:\n",
        "                    if vals.strip().startswith(\"filename=\"):\n",
        "                        filenm=unquote(vals.split(\"=\", 1)[1].strip())\n",
        "                        return filenm.replace(\"\\\"\",\"\")\n",
        "    else:\n",
        "        headers = {\"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36\"}\n",
        "        lnk=\"https://drive.google.com/uc?id={id}&export=download\".format(id=url[url.find(\"/d/\")+3:url.find(\"/view\")])\n",
        "        res = requests.session().get(lnk, headers=headers, stream=True, verify=True)\n",
        "        res = requests.session().get(get_url_from_gdrive_confirmation(res.text), headers=headers, stream=True, verify=True)\n",
        "        content_disposition = six.moves.urllib_parse.unquote(res.headers[\"Content-Disposition\"])\n",
        "        filenm = re.search('attachment; filename=\"(.*?)\"', content_disposition).groups()[0]\n",
        "        return filenm\n",
        "\n",
        "\n",
        "def dwn(url, dst, msg):\n",
        "    file_size = None\n",
        "    req = Request(url, headers={\"User-Agent\": \"torch.hub\"})\n",
        "    u = urlopen(req)\n",
        "    meta = u.info()\n",
        "    if hasattr(meta, 'getheaders'):\n",
        "        content_length = meta.getheaders(\"Content-Length\")\n",
        "    else:\n",
        "        content_length = meta.get_all(\"Content-Length\")\n",
        "    if content_length is not None and len(content_length) > 0:\n",
        "        file_size = int(content_length[0])\n",
        "\n",
        "    with tqdm(total=file_size, disable=False, mininterval=0.5,\n",
        "              bar_format=msg+' |{bar:20}| {percentage:3.0f}%') as pbar:\n",
        "        with open(dst, \"wb\") as f:\n",
        "            while True:\n",
        "                buffer = u.read(8192)\n",
        "                if len(buffer) == 0:\n",
        "                    break\n",
        "                f.write(buffer)\n",
        "                pbar.update(len(buffer))\n",
        "            f.close()\n",
        "\n",
        "\n",
        "def sdmdls(ver, Use_Temp_Storage):\n",
        "\n",
        "  if ver=='1.5':\n",
        "    if Use_Temp_Storage:\n",
        "      os.makedirs('/content/temp_models', exist_ok=True)\n",
        "      model='/content/temp_models/v1-5-pruned-emaonly.safetensors'\n",
        "    else:\n",
        "      model='/content/gdrive/'+mainpth+'/sd/stable-diffusion-w'+blsaphemy+'/models/Stable-diffusion/v1-5-pruned-emaonly.safetensors'\n",
        "    link='https://huggingface.co/runwayml/stable-diffusion-v1-5/resolve/main/v1-5-pruned-emaonly.safetensors'\n",
        "  elif ver=='V2.1-768px':\n",
        "    if Use_Temp_Storage:\n",
        "      os.makedirs('/content/temp_models', exist_ok=True)\n",
        "      model='/content/temp_models/v2-1_768-ema-pruned.safetensors'\n",
        "    else:\n",
        "      model='/content/gdrive/'+mainpth+'/sd/stable-diffusion-w'+blsaphemy+'/models/Stable-diffusion/v2-1_768-ema-pruned.safetensors'\n",
        "    link='https://huggingface.co/stabilityai/stable-diffusion-2-1/resolve/main/v2-1_768-ema-pruned.safetensors'\n",
        "  elif ver=='v1.5 Inpainting':\n",
        "    if Use_Temp_Storage:\n",
        "      os.makedirs('/content/temp_models', exist_ok=True)\n",
        "      model='/content/temp_models/sd-v1-5-inpainting.ckpt'\n",
        "    else:\n",
        "      model='/content/gdrive/'+mainpth+'/sd/stable-diffusion-w'+blsaphemy+'/models/Stable-diffusion/sd-v1-5-inpainting.ckpt'\n",
        "    link='https://huggingface.co/runwayml/stable-diffusion-inpainting/resolve/main/sd-v1-5-inpainting.ckpt'\n",
        "  elif ver=='SDXL':\n",
        "    if Use_Temp_Storage:\n",
        "      os.makedirs('/content/temp_models', exist_ok=True)\n",
        "      model='/content/temp_models/sd_xl_base_1.0.safetensors'\n",
        "    else:\n",
        "      model='/content/gdrive/'+mainpth+'/sd/stable-diffusion-w'+blsaphemy+'/models/Stable-diffusion/sd_xl_base_1.0.safetensors'\n",
        "    link='https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/resolve/main/sd_xl_base_1.0.safetensors'\n",
        "\n",
        "  if not os.path.exists(model):\n",
        "    !gdown --fuzzy -O $model $link\n",
        "    if os.path.exists(model):\n",
        "      clear_output()\n",
        "      inf('\\u2714 Done','success', '50px')\n",
        "    else:\n",
        "      inf('\\u2718 Something went wrong, try again','danger', \"250px\")\n",
        "  else:\n",
        "      clear_output()\n",
        "      inf('\\u2714 Model already exists','primary', '300px')\n",
        "\n",
        "  return model\n",
        "\n",
        "\n",
        "if (PATH_to_MODEL !=''):\n",
        "  if os.path.exists(str(PATH_to_MODEL)):\n",
        "    inf('\\u2714 Using the trained model.','success', '200px')\n",
        "\n",
        "  else:\n",
        "      while not os.path.exists(str(PATH_to_MODEL)):\n",
        "        inf('\\u2718 Wrong path, use the colab file explorer to copy the path : ','danger', \"400px\")\n",
        "        PATH_to_MODEL=input()\n",
        "      if os.path.exists(str(PATH_to_MODEL)):\n",
        "        inf('\\u2714 Using the custom model.','success', '200px')\n",
        "\n",
        "  model=PATH_to_MODEL\n",
        "\n",
        "elif MODEL_LINK != \"\":\n",
        "\n",
        "      if src=='civitai':\n",
        "         modelname=get_name(MODEL_LINK, False)\n",
        "         if Use_Temp_Storage:\n",
        "            os.makedirs('/content/temp_models', exist_ok=True)\n",
        "            model=f'/content/temp_models/{modelname}'\n",
        "         else:\n",
        "            model=f'/content/gdrive/{mainpth}/sd/stable-diffusion-w{blsaphemy}/models/Stable-diffusion/{modelname}'\n",
        "         if not os.path.exists(model):\n",
        "            dwn(MODEL_LINK, model, 'Downloading the custom model')\n",
        "            clear_output()\n",
        "         else:\n",
        "            inf('\\u2714 Model already exists','primary', '300px')\n",
        "      elif src=='gdrive':\n",
        "         modelname=get_name(MODEL_LINK, True)\n",
        "         if Use_Temp_Storage:\n",
        "            os.makedirs('/content/temp_models', exist_ok=True)\n",
        "            model=f'/content/temp_models/{modelname}'\n",
        "         else:\n",
        "            model=f'/content/gdrive/{mainpth}/sd/stable-diffusion-w{blsaphemy}/models/Stable-diffusion/{modelname}'\n",
        "         if not os.path.exists(model):\n",
        "            gdown.download(url=MODEL_LINK, output=model, quiet=False, fuzzy=True)\n",
        "            clear_output()\n",
        "         else:\n",
        "            inf('\\u2714 Model already exists','primary', '300px')\n",
        "      else:\n",
        "         modelname=os.path.basename(MODEL_LINK)\n",
        "         if Use_Temp_Storage:\n",
        "            os.makedirs('/content/temp_models', exist_ok=True)\n",
        "            model=f'/content/temp_models/{modelname}'\n",
        "         else:\n",
        "            model=f'/content/gdrive/{mainpth}/sd/stable-diffusion-w{blsaphemy}/models/Stable-diffusion/{modelname}'\n",
        "         if not os.path.exists(model):\n",
        "            gdown.download(url=MODEL_LINK, output=model, quiet=False, fuzzy=True)\n",
        "            clear_output()\n",
        "         else:\n",
        "            inf('\\u2714 Model already exists','primary', '700px')\n",
        "\n",
        "      if os.path.exists(model) and os.path.getsize(model) > 1810671599:\n",
        "        inf('\\u2714 Model downloaded, using the custom model.','success', '300px')\n",
        "      else:\n",
        "        !rm model\n",
        "        inf('\\u2718 Wrong link, check that the link is valid','danger', \"300px\")\n",
        "\n",
        "else:\n",
        "  model=sdmdls(Model_Version, Use_Temp_Storage)\n",
        "\n",
        "#@markdown ---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Svx6Hx0iUPd1"
      },
      "outputs": [],
      "source": [
        "#@markdown # Download LoRA\n",
        "\n",
        "LoRA_LINK = \"\" #@param {type:\"string\"}\n",
        "\n",
        "if LoRA_LINK == \"\":\n",
        "  inf('\\u2714 Nothing to do','primary', '200px')\n",
        "else:\n",
        "  os.makedirs('/content/gdrive/'+mainpth+'/sd/stable-diffusion-w'+blsaphemy+'/models/Lora', exist_ok=True)\n",
        "\n",
        "  src=getsrc(LoRA_LINK)\n",
        "\n",
        "  if src=='civitai':\n",
        "      modelname=get_name(LoRA_LINK, False)\n",
        "      loramodel=f'/content/gdrive/{mainpth}/sd/stable-diffusion-w{blsaphemy}/models/Lora/{modelname}'\n",
        "      if not os.path.exists(loramodel):\n",
        "        dwn(LoRA_LINK, loramodel, 'Downloading the LoRA model '+modelname)\n",
        "        clear_output()\n",
        "      else:\n",
        "        inf('\\u2714 Model already exists','primary', '200px')\n",
        "  elif src=='gdrive':\n",
        "      modelname=get_name(LoRA_LINK, True)\n",
        "      loramodel=f'/content/gdrive/{mainpth}/sd/stable-diffusion-w{blsaphemy}/models/Lora/{modelname}'\n",
        "      if not os.path.exists(loramodel):\n",
        "        gdown.download(url=LoRA_LINK, output=loramodel, quiet=False, fuzzy=True)\n",
        "        clear_output()\n",
        "      else:\n",
        "        inf('\\u2714 Model already exists','primary', '200px')\n",
        "  else:\n",
        "      modelname=os.path.basename(LoRA_LINK)\n",
        "      loramodel=f'/content/gdrive/{mainpth}/sd/stable-diffusion-w{blsaphemy}/models/Lora/{modelname}'\n",
        "      if not os.path.exists(loramodel):\n",
        "        gdown.download(url=LoRA_LINK, output=loramodel, quiet=False, fuzzy=True)\n",
        "        clear_output()\n",
        "      else:\n",
        "        inf('\\u2714 Model already exists','primary', '200px')\n",
        "\n",
        "  if os.path.exists(loramodel) :\n",
        "    inf('\\u2714 LoRA downloaded','success', '200px')\n",
        "  else:\n",
        "    inf('\\u2718 Wrong link, check that the link is valid','danger', \"300px\")\n",
        "\n",
        "#@markdown ---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "zC3Rz1b2TBcB"
      },
      "outputs": [],
      "source": [
        "#@markdown # ControlNet\n",
        "from torch.hub import download_url_to_file\n",
        "from urllib.parse import urlparse\n",
        "import re\n",
        "from subprocess import run\n",
        "\n",
        "XL_Model = \"None\" #@param [ \"None\", \"All\", \"Canny\", \"Depth\", \"Sketch\", \"OpenPose\", \"Recolor\"]\n",
        "\n",
        "v1_Model = \"None\" #@param [ \"None\", \"All (21GB)\", \"Canny\", \"Depth\", \"Lineart\", \"MLSD\", \"Normal\", \"OpenPose\", \"Scribble\", \"Seg\", \"ip2p\", \"Shuffle\", \"Inpaint\", \"Softedge\", \"Lineart_Anime\", \"Tile\", \"T2iadapter_Models\"]\n",
        "\n",
        "v2_Model = \"None\" #@param [ \"None\", \"All\", \"Canny\", \"Depth\", \"HED\", \"OpenPose\", \"Scribble\"]\n",
        "\n",
        "#@markdown - Download/update ControlNet extension and its models\n",
        "\n",
        "def download(url, model_dir):\n",
        "\n",
        "    filename = os.path.basename(urlparse(url).path)\n",
        "    pth = os.path.abspath(os.path.join(model_dir, filename))\n",
        "    if not os.path.exists(pth):\n",
        "        print('Downloading: '+os.path.basename(url))\n",
        "        download_url_to_file(url, pth, hash_prefix=None, progress=True)\n",
        "    else:\n",
        "      print(f\"\u001b[1;32mThe model {filename} already exists\u001b[0m\")\n",
        "\n",
        "\n",
        "Canny='https://huggingface.co/lllyasviel/sd_control_collection/resolve/main/diffusers_xl_canny_mid.safetensors'\n",
        "Depth='https://huggingface.co/lllyasviel/sd_control_collection/resolve/main/diffusers_xl_depth_mid.safetensors'\n",
        "Sketch='https://huggingface.co/lllyasviel/sd_control_collection/resolve/main/sai_xl_sketch_256lora.safetensors'\n",
        "OpenPose='https://huggingface.co/lllyasviel/sd_control_collection/resolve/main/thibaud_xl_openpose_256lora.safetensors'\n",
        "Recolor='https://huggingface.co/lllyasviel/sd_control_collection/resolve/main/sai_xl_recolor_128lora.safetensors'\n",
        "\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "  %cd /content/gdrive/$mainpth/sd/stable-diffusion-w$blsaphemy/extensions\n",
        "  if not os.path.exists('sd-w'+blsaphemy+'-controlnet'):\n",
        "    !git clone https://github.com/Mikubill/sd-w$blsaphemy-controlnet.git\n",
        "    %cd /content\n",
        "  else:\n",
        "    %cd sd-w$blsaphemy-controlnet\n",
        "    !git reset --hard\n",
        "    !git pull\n",
        "    %cd /content\n",
        "\n",
        "mdldir='/content/gdrive/'+mainpth+'/sd/stable-diffusion-w'+blsaphemy+'/extensions/sd-w'+blsaphemy+'-controlnet/models'\n",
        "for filename in os.listdir(mdldir):\n",
        "  if \"_sd14v1\" in filename:\n",
        "    renamed = re.sub(\"_sd14v1\", \"-fp16\", filename)\n",
        "    os.rename(os.path.join(mdldir, filename), os.path.join(mdldir, renamed))\n",
        "\n",
        "!wget -q -O CN_models.txt https://github.com/TheLastBen/fast-stable-diffusion/raw/main/AUTOMATIC1111_files/CN_models.txt\n",
        "!wget -q -O CN_models_v2.txt https://github.com/TheLastBen/fast-stable-diffusion/raw/main/AUTOMATIC1111_files/CN_models_v2.txt\n",
        "!wget -q -O CN_models_XL.txt https://github.com/TheLastBen/fast-stable-diffusion/raw/main/AUTOMATIC1111_files/CN_models_XL.txt\n",
        "\n",
        "\n",
        "with open(\"CN_models.txt\", 'r') as f:\n",
        "  mdllnk = f.read().splitlines()\n",
        "with open(\"CN_models_v2.txt\", 'r') as d:\n",
        "  mdllnk_v2 = d.read().splitlines()\n",
        "with open(\"CN_models_XL.txt\", 'r') as d:\n",
        "  mdllnk_XL = d.read().splitlines()\n",
        "\n",
        "!rm CN_models.txt CN_models_v2.txt CN_models_XL.txt\n",
        "\n",
        "\n",
        "if XL_Model == \"All\":\n",
        "  for lnk_XL in mdllnk_XL:\n",
        "      download(lnk_XL, mdldir)\n",
        "  clear_output()\n",
        "  inf('\\u2714 Done','success', '50px')\n",
        "\n",
        "elif XL_Model == \"None\":\n",
        "    pass\n",
        "    clear_output()\n",
        "    inf('\\u2714 Done','success', '50px')\n",
        "\n",
        "else:\n",
        "  download(globals()[XL_Model], mdldir)\n",
        "  clear_output()\n",
        "  inf('\\u2714 Done','success', '50px')\n",
        "\n",
        "\n",
        "Canny='https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/control_v11p_sd15_canny.pth'\n",
        "Depth='https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/control_v11f1p_sd15_depth.pth'\n",
        "Lineart='https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/control_v11p_sd15_lineart.pth'\n",
        "MLSD='https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/control_v11p_sd15_mlsd.pth'\n",
        "Normal='https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/control_v11p_sd15_normalbae.pth'\n",
        "OpenPose='https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/control_v11p_sd15_openpose.pth'\n",
        "Scribble='https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/control_v11p_sd15_scribble.pth'\n",
        "Seg='https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/control_v11p_sd15_seg.pth'\n",
        "ip2p='https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/control_v11e_sd15_ip2p.pth'\n",
        "Shuffle='https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/control_v11e_sd15_shuffle.pth'\n",
        "Inpaint='https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/control_v11p_sd15_inpaint.pth'\n",
        "Softedge='https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/control_v11p_sd15_softedge.pth'\n",
        "Lineart_Anime='https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/control_v11p_sd15s2_lineart_anime.pth'\n",
        "Tile='https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/control_v11f1e_sd15_tile.pth'\n",
        "\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "  cfgnames=[os.path.basename(url).split('.')[0]+'.yaml' for url in mdllnk_v2]\n",
        "  %cd /content/gdrive/$mainpth/sd/stable-diffusion-w$blsaphemy/extensions/sd-w$blsaphemy-controlnet/models\n",
        "  for name in cfgnames:\n",
        "      run(['cp', 'cldm_v21.yaml', name])\n",
        "  %cd /content\n",
        "\n",
        "if v1_Model == \"All (21GB)\":\n",
        "  for lnk in mdllnk:\n",
        "      download(lnk, mdldir)\n",
        "  clear_output()\n",
        "\n",
        "elif v1_Model == \"T2iadapter_Models\":\n",
        "  mdllnk=list(filter(lambda x: 't2i' in x, mdllnk))\n",
        "  for lnk in mdllnk:\n",
        "      download(lnk, mdldir)\n",
        "  clear_output()\n",
        "\n",
        "elif v1_Model == \"None\":\n",
        "    pass\n",
        "    clear_output()\n",
        "\n",
        "else:\n",
        "  download(globals()[v1_Model], mdldir)\n",
        "  clear_output()\n",
        "\n",
        "Canny='https://huggingface.co/thibaud/controlnet-sd21/resolve/main/control_v11p_sd21_canny.safetensors'\n",
        "Depth='https://huggingface.co/thibaud/controlnet-sd21/resolve/main/control_v11p_sd21_depth.safetensors'\n",
        "HED='https://huggingface.co/thibaud/controlnet-sd21/resolve/main/control_v11p_sd21_hed.safetensors'\n",
        "OpenPose='https://huggingface.co/thibaud/controlnet-sd21/resolve/main/control_v11p_sd21_openposev2.safetensors'\n",
        "Scribble='https://huggingface.co/thibaud/controlnet-sd21/resolve/main/control_v11p_sd21_scribble.safetensors'\n",
        "\n",
        "\n",
        "if v2_Model == \"All\":\n",
        "  for lnk_v2 in mdllnk_v2:\n",
        "      download(lnk_v2, mdldir)\n",
        "  clear_output()\n",
        "  inf('\\u2714 Done','success', '50px')\n",
        "\n",
        "elif v2_Model == \"None\":\n",
        "    pass\n",
        "    clear_output()\n",
        "    inf('\\u2714 Done','success', '50px')\n",
        "\n",
        "else:\n",
        "  download(globals()[v2_Model], mdldir)\n",
        "  clear_output()\n",
        "  inf('\\u2714 Done','success', '50px')\n",
        "\n",
        "  #@markdown ---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PjzwxTkPSPHf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a792dcf6-433a-45d4-b788-b74844a35d95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading weights [59225eddc3] from /content/temp_models/JANKUV4NSFWTrainedNoobaiEPS_v40.safetensors\n",
            "Creating model from config: /content/gdrive/MyDrive/sd/stablediffusion/generative-models/configs/inference/sd_xl_base.yaml\n",
            "Running on local URL: https://d3ca-35-231-79-177.ngrok-free.app\n",
            "\u001b[32m✔ Connected\n",
            "Startup time: 19.2s (import torch: 8.8s, import gradio: 2.4s, setup paths: 1.9s, initialize shared: 0.3s, other imports: 1.1s, list SD models: 0.1s, load scripts: 0.9s, create ui: 3.0s, gradio launch: 0.2s, add APIs: 0.3s).\n",
            "Applying attention optimization: xformers... done.\n",
            "Calculating sha256 for /content/gdrive/MyDrive/sd/stable-diffusion-webui/embeddings/lazypos.safetensors: 30866692653cb0063484dec240bc7971adc5767753b0cbbe072e2ddd7ff16b81\n",
            "Model loaded in 33.8s (load weights from disk: 1.4s, create model: 2.2s, apply weights to model: 28.4s, load textual inversion embeddings: 0.5s, calculate empty prompt: 1.0s).\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/routes.py\", line 488, in run_predict\n",
            "    output = await app.get_blocks().process_api(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 1435, in process_api\n",
            "    result = await self.call_function(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 1107, in call_function\n",
            "    prediction = await anyio.to_thread.run_sync(\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/to_thread.py\", line 31, in run_sync\n",
            "    return await get_asynclib().run_sync_in_worker_thread(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/_backends/_asyncio.py\", line 937, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/_backends/_asyncio.py\", line 867, in run\n",
            "    result = context.run(func, *args)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/utils.py\", line 707, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/extensions/embedding-inspector/scripts/embedding_inspector.py\", line 157, in do_inspect\n",
            "    emb_name, emb_id, emb_vec, loaded_emb = get_embedding_info(text)\n",
            "                                            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/extensions/embedding-inspector/scripts/embedding_inspector.py\", line 116, in get_embedding_info\n",
            "    emb_id = '['+loaded_emb.checksum()+']' # emb_id is string for loaded embeddings\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/textual_inversion/textual_inversion.py\", line 83, in checksum\n",
            "    self.cached_checksum = f'{const_hash(self.vec.reshape(-1) * 100) & 0xffff:04x}'\n",
            "                                         ^^^^^^^^^^^^^^^^\n",
            "AttributeError: 'dict' object has no attribute 'reshape'\n",
            "100% 30/30 [00:41<00:00,  1.39s/it]\n",
            "100% 30/30 [00:40<00:00,  1.35s/it]\n",
            "100% 30/30 [00:40<00:00,  1.34s/it]\n",
            "100% 30/30 [00:42<00:00,  1.42s/it]\n",
            "100% 30/30 [00:42<00:00,  1.42s/it]\n",
            "100% 20/20 [00:28<00:00,  1.40s/it]\n",
            "100% 25/25 [00:35<00:00,  1.42s/it]\n",
            " 50% 15/30 [00:20<00:21,  1.43s/it]Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/routes.py\", line 488, in run_predict\n",
            "    output = await app.get_blocks().process_api(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 1435, in process_api\n",
            "    result = await self.call_function(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 1107, in call_function\n",
            "    prediction = await anyio.to_thread.run_sync(\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/to_thread.py\", line 31, in run_sync\n",
            "    return await get_asynclib().run_sync_in_worker_thread(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/_backends/_asyncio.py\", line 937, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/_backends/_asyncio.py\", line 867, in run\n",
            "    result = context.run(func, *args)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/utils.py\", line 707, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/extensions/embedding-inspector/scripts/embedding_inspector.py\", line 157, in do_inspect\n",
            "    emb_name, emb_id, emb_vec, loaded_emb = get_embedding_info(text)\n",
            "                                            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/extensions/embedding-inspector/scripts/embedding_inspector.py\", line 116, in get_embedding_info\n",
            "    emb_id = '['+loaded_emb.checksum()+']' # emb_id is string for loaded embeddings\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/textual_inversion/textual_inversion.py\", line 83, in checksum\n",
            "    self.cached_checksum = f'{const_hash(self.vec.reshape(-1) * 100) & 0xffff:04x}'\n",
            "                                         ^^^^^^^^^^^^^^^^\n",
            "AttributeError: 'dict' object has no attribute 'reshape'\n",
            "100% 30/30 [00:42<00:00,  1.42s/it]\n",
            "Downloading: \"https://github.com/xinntao/Real-ESRGAN/releases/download/v0.1.0/RealESRGAN_x4plus.pth\" to /content/gdrive/MyDrive/sd/stable-diffusion-webui/models/RealESRGAN/RealESRGAN_x4plus.pth\n",
            "\n",
            "100% 63.9M/63.9M [00:00<00:00, 206MB/s]\n",
            "tiled upscale 94% 51/54 [00:12<00:00,  4.06it/s]\n",
            "*** Error completing request\n",
            "*** Arguments: ('task(0p6clax9t6xwswf)', <gradio.routes.Request object at 0x7a56db766590>, 'lazypos, lazyloli, beach, bystanders in ((distance)), showing back ass pussy, (view angled from floor upwards), perverted grin with tounge, yellow eyes, oiled, small, (standing with arms behind back:1.2), (one hand stretching ass:2), bended backwards towards viewer, head turned to viewer, oiled skin:0.7', 'lazyneg', [], 1, 1, 3.5, 1536, 1024, True, 0.7, 1.5, 'R-ESRGAN 4x+', 0, 0, 0, 'Use same checkpoint', 'Use same sampler', 'Use same scheduler', '', '', [], 0, 30, 'Euler a', 'SGM Uniform', False, '', 0.8, -1, False, -1, 0, 0, 0, False, False, 'positive', 'comma', 0, False, False, 'start', '', 1, '', [], 0, '', [], 0, '', [], True, False, False, False, False, False, False, 0, False) {}\n",
            "    Traceback (most recent call last):\n",
            "      File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/call_queue.py\", line 74, in f\n",
            "        res = list(func(*args, **kwargs))\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/call_queue.py\", line 53, in f\n",
            "        res = func(*args, **kwargs)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/call_queue.py\", line 37, in f\n",
            "        res = func(*args, **kwargs)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/txt2img.py\", line 109, in txt2img\n",
            "        processed = processing.process_images(p)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/processing.py\", line 847, in process_images\n",
            "        res = process_images_inner(p)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/processing.py\", line 988, in process_images_inner\n",
            "        samples_ddim = p.sample(conditioning=p.c, unconditional_conditioning=p.uc, seeds=p.seeds, subseeds=p.subseeds, subseed_strength=p.subseed_strength, prompts=p.prompts)\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/processing.py\", line 1362, in sample\n",
            "        return self.sample_hr_pass(samples, decoded_samples, seeds, subseeds, subseed_strength, prompts)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/processing.py\", line 1421, in sample_hr_pass\n",
            "        samples = images_tensor_to_samples(decoded_samples, approximation_indexes.get(opts.sd_vae_encode_method))\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/sd_samplers_common.py\", line 110, in images_tensor_to_samples\n",
            "        x_latent = model.get_first_stage_encoding(model.encode_first_stage(image))\n",
            "                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "        return func(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/gdrive/MyDrive/sd/stablediffusion/generative-models/sgm/models/diffusion.py\", line 127, in encode_first_stage\n",
            "        z = self.first_stage_model.encode(x)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/gdrive/MyDrive/sd/stablediffusion/generative-models/sgm/models/autoencoder.py\", line 321, in encode\n",
            "        return super().encode(x).sample()\n",
            "               ^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/gdrive/MyDrive/sd/stablediffusion/generative-models/sgm/models/autoencoder.py\", line 308, in encode\n",
            "        h = self.encoder(x)\n",
            "            ^^^^^^^^^^^^^^^\n",
            "      File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
            "        return self._call_impl(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
            "        return forward_call(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/gdrive/MyDrive/sd/stablediffusion/generative-models/sgm/modules/diffusionmodules/model.py\", line 579, in forward\n",
            "        h = self.down[i_level].block[i_block](hs[-1], temb)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
            "        return self._call_impl(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
            "        return forward_call(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/gdrive/MyDrive/sd/stablediffusion/generative-models/sgm/modules/diffusionmodules/model.py\", line 131, in forward\n",
            "        h = nonlinearity(h)\n",
            "            ^^^^^^^^^^^^^^^\n",
            "      File \"/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py\", line 2380, in silu\n",
            "        return torch._C._nn.silu(input)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.69 GiB. GPU 0 has a total capacity of 14.74 GiB of which 1.05 GiB is free. Process 198985 has 13.69 GiB memory in use. Of the allocated memory 11.88 GiB is allocated by PyTorch, and 1.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "\n",
            "---\n",
            "100% 25/25 [00:35<00:00,  1.40s/it]\n",
            "100% 25/25 [00:35<00:00,  1.42s/it]\n",
            "100% 25/25 [00:33<00:00,  1.34s/it]\n",
            "100% 25/25 [00:33<00:00,  1.33s/it]\n",
            "100% 25/25 [00:34<00:00,  1.39s/it]\n",
            "100% 30/30 [00:39<00:00,  1.32s/it]\n",
            "100% 30/30 [00:40<00:00,  1.35s/it]\n",
            "100% 30/30 [00:40<00:00,  1.33s/it]\n",
            "100% 30/30 [00:39<00:00,  1.33s/it]\n",
            "100% 30/30 [00:39<00:00,  1.32s/it]\n",
            "100% 30/30 [00:40<00:00,  1.34s/it]\n",
            "100% 30/30 [00:40<00:00,  1.33s/it]\n",
            "100% 30/30 [00:25<00:00,  1.19it/s]\n",
            "100% 30/30 [00:25<00:00,  1.18it/s]\n",
            "100% 25/25 [00:20<00:00,  1.20it/s]\n",
            "100% 25/25 [00:21<00:00,  1.18it/s]\n",
            "100% 25/25 [00:20<00:00,  1.20it/s]\n",
            "100% 25/25 [00:20<00:00,  1.19it/s]\n",
            "100% 25/25 [00:20<00:00,  1.21it/s]\n",
            "100% 25/25 [00:22<00:00,  1.13it/s]\n",
            "100% 25/25 [00:22<00:00,  1.11it/s]\n",
            "100% 25/25 [00:22<00:00,  1.13it/s]\n",
            "100% 25/25 [00:23<00:00,  1.04it/s]\n",
            "100% 25/25 [00:23<00:00,  1.05it/s]\n"
          ]
        }
      ],
      "source": [
        "#@markdown # Start Stable-Diffusion\n",
        "from IPython.utils import capture\n",
        "import time\n",
        "import sys\n",
        "import fileinput\n",
        "from pyngrok import ngrok, conf\n",
        "import re\n",
        "\n",
        "\n",
        "Ngrok_token = \"2lJICAmwwaIkg9dyQqBvy9o7c2b_5MwD1krUSPsMSfw7EkxMn\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown - Input your ngrok token if you want to use ngrok server\n",
        "\n",
        "User = \"szymek\" #@param {type:\"string\"}\n",
        "Password= \"1337cd\" #@param {type:\"string\"}\n",
        "#@markdown - Add credentials to your Gradio interface (optional)\n",
        "\n",
        "auth=f\"--gradio-auth {User}:{Password}\"\n",
        "if User ==\"\" or Password==\"\":\n",
        "  auth=\"\"\n",
        "\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "  %cd /content/gdrive/$mainpth/sd/stable-diffusion-w$blsaphemy/modules/\n",
        "  !wget -q -O extras.py https://raw.githubusercontent.com/AUTOMATIC1111/stable-diffusion-w$blsaphemy/master/modules/extras.py\n",
        "  #!wget -q -O sd_models.py https://raw.githubusercontent.com/AUTOMATIC1111/stable-diffusion-w$blsaphemy/master/modules/sd_models.py\n",
        "  !wget -q -O /usr/local/lib/python3.11/dist-packages/gradio/blocks.py https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/AUTOMATIC1111_files/blocks.py\n",
        "  %cd /content/gdrive/$mainpth/sd/stable-diffusion-w$blsaphemy/\n",
        "\n",
        "  !sed -i 's@shared.opts.data\\[\"sd_model_checkpoint\"] = checkpoint_info.title@shared.opts.data\\[\"sd_model_checkpoint\"] = checkpoint_info.title;model.half()@' /content/gdrive/$mainpth/sd/stable-diffusion-w$blsaphemy/modules/sd_models.py\n",
        "  #!sed -i 's@ui.create_ui().*@ui.create_ui();shared.demo.queue(concurrency_count=999999,status_update_rate=0.1)@' /content/gdrive/$mainpth/sd/stable-diffusion-w$blsaphemy/webui.py\n",
        "  !sed -i \"s@map_location='cpu'@map_location='cuda'@\" /content/gdrive/$mainpth/sd/stable-diffusion-w$blsaphemy/modules/extras.py\n",
        "\n",
        "  !sed -i 's@possible_sd_paths =.*@possible_sd_paths = [\\\"/content/gdrive/{mainpth}/sd/stablediffusion\\\"]@' /content/gdrive/$mainpth/sd/stable-diffusion-w$blsaphemy/modules/paths.py\n",
        "  !sed -i 's@\\.\\.\\/@src/@g' /content/gdrive/$mainpth/sd/stable-diffusion-w$blsaphemy/modules/paths.py\n",
        "  !sed -i 's@src/generative-models@generative-models@g' /content/gdrive/$mainpth/sd/stable-diffusion-w$blsaphemy/modules/paths.py\n",
        "\n",
        "  !sed -i 's@print(\\\"No module.*@@' /content/gdrive/$mainpth/sd/stablediffusion/ldm/modules/diffusionmodules/model.py\n",
        "  !sed -i 's@\\[\"sd_model_checkpoint\"\\]@\\[\"sd_model_checkpoint\", \"sd_vae\", \"CLIP_stop_at_last_layers\", \"inpainting_mask_weight\", \"initial_noise_multiplier\"\\]@g' /content/gdrive/$mainpth/sd/stable-diffusion-w$blsaphemy/modules/shared.py\n",
        "\n",
        "share=''\n",
        "if Ngrok_token!=\"\":\n",
        "  ngrok.kill()\n",
        "  srv=ngrok.connect(7860, pyngrok_config=conf.PyngrokConfig(auth_token=Ngrok_token) , bind_tls=True).public_url\n",
        "\n",
        "  for line in fileinput.input('/usr/local/lib/python3.11/dist-packages/gradio/blocks.py', inplace=True):\n",
        "    if line.strip().startswith('self.server_name ='):\n",
        "        line = f'            self.server_name = \"{srv[8:]}\"\\n'\n",
        "    if line.strip().startswith('self.protocol = \"https\"'):\n",
        "        line = '            self.protocol = \"https\"\\n'\n",
        "    if line.strip().startswith('if self.local_url.startswith(\"https\") or self.is_colab'):\n",
        "        line = ''\n",
        "    if line.strip().startswith('else \"http\"'):\n",
        "        line = ''\n",
        "    sys.stdout.write(line)\n",
        "else:\n",
        "  share='--share'\n",
        "\n",
        "ckptdir=''\n",
        "if os.path.exists('/content/temp_models'):\n",
        "  ckptdir='--ckpt-dir /content/temp_models'\n",
        "\n",
        "try:\n",
        "  model = '/content/temp_models/JANKUV4NSFWTrainedNoobaiEPS_v40.safetensors'\n",
        "  if os.path.isfile(model):\n",
        "    !python /content/gdrive/$mainpth/sd/stable-diffusion-w$blsaphemy/webui.py $share --api --disable-safe-unpickle --enable-insecure-extension-access --no-download-sd-model --no-half-vae  --ckpt \"$model\" --xformers $auth --disable-console-progressbars --skip-version-check $ckptdir\n",
        "  else:\n",
        "    !python /content/gdrive/$mainpth/sd/stable-diffusion-w$blsaphemy/webui.py $share --api --disable-safe-unpickle --enable-insecure-extension-access --no-download-sd-model --no-half-vae  --ckpt-dir \"$model\" --xformers $auth --disable-console-progressbars --skip-version-check\n",
        "except:\n",
        "   !python /content/gdrive/$mainpth/sd/stable-diffusion-w$blsaphemy/webui.py $share --api --disable-safe-unpickle --enable-insecure-extension-access --no-download-sd-model --no-half-vae --xformers $auth --disable-console-progressbars --skip-version-check $ckptdir"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4ed3eba5e6dd4a65bfc6226d50c9ee50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "success",
            "description": "✔ Done",
            "disabled": true,
            "icon": "",
            "layout": "IPY_MODEL_24787703db6a4e91b0d4b26785f7a4be",
            "style": "IPY_MODEL_49a2b5c8e20e4639a63c3deb66f718d2",
            "tooltip": ""
          }
        },
        "24787703db6a4e91b0d4b26785f7a4be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": "50px",
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49a2b5c8e20e4639a63c3deb66f718d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "461e024356d14032b6a5d8c926f4fc76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "success",
            "description": "✔ Done",
            "disabled": true,
            "icon": "",
            "layout": "IPY_MODEL_b7034d13a1314e52b3ce38764988c488",
            "style": "IPY_MODEL_19f16ccd7c0148638b7f68d01fdddc0f",
            "tooltip": ""
          }
        },
        "b7034d13a1314e52b3ce38764988c488": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": "50px",
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19f16ccd7c0148638b7f68d01fdddc0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "d6442e75ce3344df8f7c38c8d6cb75c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "success",
            "description": "✔ Done",
            "disabled": true,
            "icon": "",
            "layout": "IPY_MODEL_b02077bf283d4fd296fb70bc69d6d5e9",
            "style": "IPY_MODEL_6a7da0e852a94a92b0a0ae1759f107cc",
            "tooltip": ""
          }
        },
        "b02077bf283d4fd296fb70bc69d6d5e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": "50px",
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a7da0e852a94a92b0a0ae1759f107cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "5d7cb8b4df604cdeb8a6fd426ee4e023": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "success",
            "description": "✔ Model downloaded, using the custom model.",
            "disabled": true,
            "icon": "",
            "layout": "IPY_MODEL_0ca3c9762cd1460e86b62e0d59a3c967",
            "style": "IPY_MODEL_7812a22b722f46a5a38b893838ffdfb6",
            "tooltip": ""
          }
        },
        "0ca3c9762cd1460e86b62e0d59a3c967": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": "300px",
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7812a22b722f46a5a38b893838ffdfb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}